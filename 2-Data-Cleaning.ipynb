{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "# Used for text preprocessing/nlp\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "\n",
    "import langid # !pip install langid\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "\n",
    "#!pip install emoji --upgrade\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# Used to disable printing warnings \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pickle(filename):\n",
    "    with open(filename+\".pkl\", 'rb') as read_file:\n",
    "        obj = pickle.load(read_file)\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>biography</th>\n",
       "      <th>captions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>username</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ladyandpups</td>\n",
       "      <td>Our cookbook - THE ART OF ESCAPISM COOKING - I...</td>\n",
       "      <td>[Thank you guys for tuning in on my Instagram ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>nelrestaurant</td>\n",
       "      <td>Unique dining experience full of surprises, tu...</td>\n",
       "      <td>[Planning a Christmas function? üéÖ.\\n.\\nBe it b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cookrepublic</td>\n",
       "      <td>Award Winning PHOTOGRAPHER/ BLOGGER/ STYLIST/ ...</td>\n",
       "      <td>[It‚Äôs too hot for soup! But nourishing soups a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>annabarnettcooks</td>\n",
       "      <td>COOK | AUTHOR | EVENING STANDARD CONTRIBUTOR |...</td>\n",
       "      <td>[{Collab} As always Ted was star of the show o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dennistheprescott</td>\n",
       "      <td>I cook, I photograph, I write. All homemade. M...</td>\n",
       "      <td>[Monday Drip. üç™ü•õüí¶ (recipe in my cookbook) Have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>eatsmorefun</td>\n",
       "      <td>All üì∑ are ours\\nüìçCurrently Featuring: Singapor...</td>\n",
       "      <td>[Black Pepper Cream Crab Linguini \\n________\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>igbrunchclub</td>\n",
       "      <td>Use our hashtag #IGBrunchClub for a chance to ...</td>\n",
       "      <td>[Coffee and cake for breakfast @jacobtheangell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>stevehansenimages</td>\n",
       "      <td>Photographer | Director | Retoucher | CG Artis...</td>\n",
       "      <td>[Yes, it is national mushroom day.\\n-\\n#foodph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cookieandkate</td>\n",
       "      <td>Celebrating whole foods! Find my vegetarian re...</td>\n",
       "      <td>[Today, I‚Äôm rounding up thirteen of my pumpkin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           biography  \\\n",
       "username                                                               \n",
       "ladyandpups        Our cookbook - THE ART OF ESCAPISM COOKING - I...   \n",
       "nelrestaurant      Unique dining experience full of surprises, tu...   \n",
       "cookrepublic       Award Winning PHOTOGRAPHER/ BLOGGER/ STYLIST/ ...   \n",
       "annabarnettcooks   COOK | AUTHOR | EVENING STANDARD CONTRIBUTOR |...   \n",
       "dennistheprescott  I cook, I photograph, I write. All homemade. M...   \n",
       "eatsmorefun        All üì∑ are ours\\nüìçCurrently Featuring: Singapor...   \n",
       "igbrunchclub       Use our hashtag #IGBrunchClub for a chance to ...   \n",
       "stevehansenimages  Photographer | Director | Retoucher | CG Artis...   \n",
       "cookieandkate      Celebrating whole foods! Find my vegetarian re...   \n",
       "\n",
       "                                                            captions  \n",
       "username                                                              \n",
       "ladyandpups        [Thank you guys for tuning in on my Instagram ...  \n",
       "nelrestaurant      [Planning a Christmas function? üéÖ.\\n.\\nBe it b...  \n",
       "cookrepublic       [It‚Äôs too hot for soup! But nourishing soups a...  \n",
       "annabarnettcooks   [{Collab} As always Ted was star of the show o...  \n",
       "dennistheprescott  [Monday Drip. üç™ü•õüí¶ (recipe in my cookbook) Have...  \n",
       "eatsmorefun        [Black Pepper Cream Crab Linguini \\n________\\n...  \n",
       "igbrunchclub       [Coffee and cake for breakfast @jacobtheangell...  \n",
       "stevehansenimages  [Yes, it is national mushroom day.\\n-\\n#foodph...  \n",
       "cookieandkate      [Today, I‚Äôm rounding up thirteen of my pumpkin...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_pickle('influencers_data')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_data = df.loc[:,['captions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_data = df.loc[:,['biography']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags_data = pd.DataFrame('', index=df.index, columns=['hashtags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "emojis_data = pd.DataFrame('', index=df.index, columns=['emojis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emojis</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>username</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ladyandpups</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>nelrestaurant</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cookrepublic</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>annabarnettcooks</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dennistheprescott</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>eatsmorefun</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>igbrunchclub</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>stevehansenimages</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cookieandkate</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  emojis\n",
       "username                \n",
       "ladyandpups             \n",
       "nelrestaurant           \n",
       "cookrepublic            \n",
       "annabarnettcooks        \n",
       "dennistheprescott       \n",
       "eatsmorefun             \n",
       "igbrunchclub            \n",
       "stevehansenimages       \n",
       "cookieandkate           "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emojis_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(captions_data.shape[0]):\n",
    "    captions_data['captions'][i] = ''.join(captions_data['captions'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Extract hashtags from captions as a feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>username</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ladyandpups</td>\n",
       "      <td>[ladyandpupscookbook, theartofescapismcooking,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>nelrestaurant</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cookrepublic</td>\n",
       "      <td>[thebakefeed, feedfeedbaking, applerecipes, ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>annabarnettcooks</td>\n",
       "      <td>[HouseOfMolteni, MyVictorinoxTake, Ryvitafibre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dennistheprescott</td>\n",
       "      <td>[TraegerCulinaryWeekend, TraegerCulinaryCase, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>eatsmorefun</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>igbrunchclub</td>\n",
       "      <td>[igbrunchclub, igbrunchclubrecommends, Circolo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>stevehansenimages</td>\n",
       "      <td>[foodphotography, motion, instafood, foodstagr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cookieandkate</td>\n",
       "      <td>[cookieandkate, pumpkin, fall, vegetarian, fee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            hashtags\n",
       "username                                                            \n",
       "ladyandpups        [ladyandpupscookbook, theartofescapismcooking,...\n",
       "nelrestaurant                                                     []\n",
       "cookrepublic       [thebakefeed, feedfeedbaking, applerecipes, ap...\n",
       "annabarnettcooks   [HouseOfMolteni, MyVictorinoxTake, Ryvitafibre...\n",
       "dennistheprescott  [TraegerCulinaryWeekend, TraegerCulinaryCase, ...\n",
       "eatsmorefun                                                       []\n",
       "igbrunchclub       [igbrunchclub, igbrunchclubrecommends, Circolo...\n",
       "stevehansenimages  [foodphotography, motion, instafood, foodstagr...\n",
       "cookieandkate      [cookieandkate, pumpkin, fall, vegetarian, fee..."
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_hashtags(text):\n",
    "    '''\n",
    "    a function for extracting hashtags text from the punctuation\n",
    "    '''\n",
    "    hashtags = re.findall(r\"#(\\w+)\", text)\n",
    "    return hashtags\n",
    "\n",
    "hashtags_data['hashtags'] = captions_data['captions'].apply(extract_hashtags)\n",
    "hashtags_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Extract Emojis from captions as a feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0x1f373\n"
     ]
    }
   ],
   "source": [
    "def extract_emojis(text):\n",
    "    '''\n",
    "    a function for extracting Emojis from the captions text\n",
    "    '''\n",
    "    emojis = re.findall(r\"#(\\w+)\", text)\n",
    "    em = \"['\\U0001F300-\\U0001F5FF'|'\\U0001F600-\\U0001F64F'|'\\U0001F680-\\U0001F9FF'|'\\u2600-\\u26FF\\u2700-\\u27BF']\"\n",
    "    emojis = regexp_tokenize(text, em)    \n",
    "    return emojis\n",
    "\n",
    "emojis_data['emojis'] = captions_data['captions'].apply(extract_emojis)\n",
    "emojis_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>captions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>username</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ladyandpups</td>\n",
       "      <td>Thank you guys for tuning in on my Instagram L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>nelrestaurant</td>\n",
       "      <td>Planning a Christmas function üéÖ Be it big or s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cookrepublic</td>\n",
       "      <td>It‚Äôs too hot for soup But nourishing soups are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>annabarnettcooks</td>\n",
       "      <td>Collab As always Ted was star of the show on a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dennistheprescott</td>\n",
       "      <td>Monday Drip üç™ü•õüí¶ recipe in my cookbook Have the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>eatsmorefun</td>\n",
       "      <td>Black Pepper Cream Crab Linguini Fremantle Sea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>igbrunchclub</td>\n",
       "      <td>Coffee and cake for breakfast jacobtheangellon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>stevehansenimages</td>\n",
       "      <td>Yes it is national mushroom day If it‚Äôs not de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cookieandkate</td>\n",
       "      <td>Today I‚Äôm rounding up thirteen of my pumpkin r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            captions\n",
       "username                                                            \n",
       "ladyandpups        Thank you guys for tuning in on my Instagram L...\n",
       "nelrestaurant      Planning a Christmas function üéÖ Be it big or s...\n",
       "cookrepublic       It‚Äôs too hot for soup But nourishing soups are...\n",
       "annabarnettcooks   Collab As always Ted was star of the show on a...\n",
       "dennistheprescott  Monday Drip üç™ü•õüí¶ recipe in my cookbook Have the...\n",
       "eatsmorefun        Black Pepper Cream Crab Linguini Fremantle Sea...\n",
       "igbrunchclub       Coffee and cake for breakfast jacobtheangellon...\n",
       "stevehansenimages  Yes it is national mushroom day If it‚Äôs not de...\n",
       "cookieandkate      Today I‚Äôm rounding up thirteen of my pumpkin r..."
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_hashtags(text):\n",
    "    text = \" \".join(filter(lambda x:x[0]!='#', text.split()))\n",
    "    return text\n",
    "captions_data['captions'] = captions_data['captions'].apply(remove_hashtags)\n",
    "captions_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Remove hashtags from the captions text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Remove punctuation / Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    '''\n",
    "    a function for removing punctuation\n",
    "    '''\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(translator)#[i.translate(translator) for i in text]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>captions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>username</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ladyandpups</td>\n",
       "      <td>Thank you guys for tuning in on my Instagram L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>nelrestaurant</td>\n",
       "      <td>Planning a Christmas function üéÖ Be it big or s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cookrepublic</td>\n",
       "      <td>It‚Äôs too hot for soup But nourishing soups are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>annabarnettcooks</td>\n",
       "      <td>Collab As always Ted was star of the show on a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dennistheprescott</td>\n",
       "      <td>Monday Drip üç™ü•õüí¶ recipe in my cookbook Have the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>eatsmorefun</td>\n",
       "      <td>Black Pepper Cream Crab Linguini Fremantle Sea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>igbrunchclub</td>\n",
       "      <td>Coffee and cake for breakfast jacobtheangellon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>stevehansenimages</td>\n",
       "      <td>Yes it is national mushroom day If it‚Äôs not de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cookieandkate</td>\n",
       "      <td>Today I‚Äôm rounding up thirteen of my pumpkin r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            captions\n",
       "username                                                            \n",
       "ladyandpups        Thank you guys for tuning in on my Instagram L...\n",
       "nelrestaurant      Planning a Christmas function üéÖ Be it big or s...\n",
       "cookrepublic       It‚Äôs too hot for soup But nourishing soups are...\n",
       "annabarnettcooks   Collab As always Ted was star of the show on a...\n",
       "dennistheprescott  Monday Drip üç™ü•õüí¶ recipe in my cookbook Have the...\n",
       "eatsmorefun        Black Pepper Cream Crab Linguini Fremantle Sea...\n",
       "igbrunchclub       Coffee and cake for breakfast jacobtheangellon...\n",
       "stevehansenimages  Yes it is national mushroom day If it‚Äôs not de...\n",
       "cookieandkate      Today I‚Äôm rounding up thirteen of my pumpkin r..."
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions_data['captions'] = captions_data['captions'].apply(remove_punctuation)\n",
    "captions_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_clean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-218-1e6409ecf61c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdata_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_clean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranscript\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdata_dtm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdata_dtm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_clean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_clean' is not defined"
     ]
    }
   ],
   "source": [
    "# We are going to create a document-term matrix using CountVectorizer, and exclude common English stop words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "data_cv = cv.fit_transform(data_clean.transcript)\n",
    "data_dtm = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "data_dtm.index = data_clean.index\n",
    "data_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>biography</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>username</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ladyandpups</td>\n",
       "      <td>Our cookbook  THE ART OF ESCAPISM COOKING  IS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>nelrestaurant</td>\n",
       "      <td>Unique dining experience full of surprises tuc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cookrepublic</td>\n",
       "      <td>Award Winning PHOTOGRAPHER BLOGGER STYLIST DES...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>annabarnettcooks</td>\n",
       "      <td>COOK  AUTHOR  EVENING STANDARD CONTRIBUTOR  FO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dennistheprescott</td>\n",
       "      <td>I cook I photograph I write All homemade My co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>eatsmorefun</td>\n",
       "      <td>All üì∑ are ours\\nüìçCurrently Featuring Singapore üá∏üá¨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>igbrunchclub</td>\n",
       "      <td>Use our hashtag IGBrunchClub for a chance to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>stevehansenimages</td>\n",
       "      <td>Photographer  Director  Retoucher  CG Artist\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cookieandkate</td>\n",
       "      <td>Celebrating whole foods Find my vegetarian rec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           biography\n",
       "username                                                            \n",
       "ladyandpups        Our cookbook  THE ART OF ESCAPISM COOKING  IS ...\n",
       "nelrestaurant      Unique dining experience full of surprises tuc...\n",
       "cookrepublic       Award Winning PHOTOGRAPHER BLOGGER STYLIST DES...\n",
       "annabarnettcooks   COOK  AUTHOR  EVENING STANDARD CONTRIBUTOR  FO...\n",
       "dennistheprescott  I cook I photograph I write All homemade My co...\n",
       "eatsmorefun        All üì∑ are ours\\nüìçCurrently Featuring Singapore üá∏üá¨\n",
       "igbrunchclub       Use our hashtag IGBrunchClub for a chance to b...\n",
       "stevehansenimages  Photographer  Director  Retoucher  CG Artist\\n...\n",
       "cookieandkate      Celebrating whole foods Find my vegetarian rec..."
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bio_data['biography'] = bio_data['biography'].apply(remove_punctuation)\n",
    "bio_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "em = re.findall('[^\\w\\s]',captions_data['captions'][0])\n",
    "# type(re.findall(r'[^\\w\\s,]', captions_data['captions'][0]))\n",
    "# def extract_emojis(sentence):\n",
    "#     return [word for word in sentence.split() if str(word.encode('unicode-escape'))[2] == '\\\\' ]\n",
    "\n",
    "# extract_emojis(captions_data['captions'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>biography</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>username</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ladyandpups</td>\n",
       "      <td>Our cookbook  THE ART OF ESCAPISM COOKING  IS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>nelrestaurant</td>\n",
       "      <td>Unique dining experience full of surprises tuc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cookrepublic</td>\n",
       "      <td>Award Winning PHOTOGRAPHER BLOGGER STYLIST DES...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>annabarnettcooks</td>\n",
       "      <td>COOK  AUTHOR  EVENING STANDARD CONTRIBUTOR  FO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dennistheprescott</td>\n",
       "      <td>I cook I photograph I write All homemade My co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>eatsmorefun</td>\n",
       "      <td>All  are ours\\nCurrently Featuring Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>igbrunchclub</td>\n",
       "      <td>Use our hashtag IGBrunchClub for a chance to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>stevehansenimages</td>\n",
       "      <td>Photographer  Director  Retoucher  CG Artist\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cookieandkate</td>\n",
       "      <td>Celebrating whole foods Find my vegetarian rec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           biography\n",
       "username                                                            \n",
       "ladyandpups        Our cookbook  THE ART OF ESCAPISM COOKING  IS ...\n",
       "nelrestaurant      Unique dining experience full of surprises tuc...\n",
       "cookrepublic       Award Winning PHOTOGRAPHER BLOGGER STYLIST DES...\n",
       "annabarnettcooks   COOK  AUTHOR  EVENING STANDARD CONTRIBUTOR  FO...\n",
       "dennistheprescott  I cook I photograph I write All homemade My co...\n",
       "eatsmorefun            All  are ours\\nCurrently Featuring Singapore \n",
       "igbrunchclub       Use our hashtag IGBrunchClub for a chance to b...\n",
       "stevehansenimages  Photographer  Director  Retoucher  CG Artist\\n...\n",
       "cookieandkate      Celebrating whole foods Find my vegetarian rec..."
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove Emojis id lan\n",
    "captions_data[\"captions\"] = captions_data['captions'].str.replace('[^\\w\\s]','') #remove emojis\n",
    "bio_data['biography'] = bio_data['biography'].str.replace('[^\\w\\s]','') #remove emojis\n",
    "# def identify_language(row):\n",
    "#     lang = langid.classify(row['captions'])\n",
    "#     return lang[0]\n",
    "\n",
    "# dataText['language'] = dataText.apply(identify_language,axis=1)\n",
    "captions_data.head(20)\n",
    "bio_data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Make text all lower case / Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>captions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>username</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ladyandpups</td>\n",
       "      <td>thank guys tuning instagram live qa last night...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>nelrestaurant</td>\n",
       "      <td>planning christmas function big small bring ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cookrepublic</td>\n",
       "      <td>hot soup nourishing soups daily part nicks rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>annabarnettcooks</td>\n",
       "      <td>collab always ted star show shoot iwe moltenid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dennistheprescott</td>\n",
       "      <td>monday drip recipe cookbook best day yall also...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>eatsmorefun</td>\n",
       "      <td>black pepper cream crab linguini fremantle sea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>igbrunchclub</td>\n",
       "      <td>coffee cake breakfast jacobtheangellondon neal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>stevehansenimages</td>\n",
       "      <td>yes national mushroom day dessert day pie stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cookieandkate</td>\n",
       "      <td>today im rounding thirteen pumpkin recipes muf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            captions\n",
       "username                                                            \n",
       "ladyandpups        thank guys tuning instagram live qa last night...\n",
       "nelrestaurant      planning christmas function big small bring ma...\n",
       "cookrepublic       hot soup nourishing soups daily part nicks rec...\n",
       "annabarnettcooks   collab always ted star show shoot iwe moltenid...\n",
       "dennistheprescott  monday drip recipe cookbook best day yall also...\n",
       "eatsmorefun        black pepper cream crab linguini fremantle sea...\n",
       "igbrunchclub       coffee cake breakfast jacobtheangellondon neal...\n",
       "stevehansenimages  yes national mushroom day dessert day pie stan...\n",
       "cookieandkate      today im rounding thirteen pumpkin recipes muf..."
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# everything lower case and removed stopwords\n",
    "from nltk.corpus import stopwords\n",
    "sw = stopwords.words('english')\n",
    "np.array(sw)\n",
    "def stopwords(text):\n",
    "    text = [word.lower()for word in text.split() if word.lower() not in sw]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def lower(text):\n",
    "    text = [word.lower() for word in text.split()]\n",
    "    return \" \".join(text)\n",
    "captions_data['captions'] = captions_data['captions'].apply(stopwords)\n",
    "captions_data\n",
    "\n",
    "bio_data['biography'] = bio_data['biography'].apply(stopwords)\n",
    "captions_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Tokenize text / Stemming text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## first tokenize, then stemmer, then vectorize into number\n",
    "stemmer = SnowballStemmer('english')\n",
    "def tokenize_stem(row):\n",
    "    stem_result = []\n",
    "    #input_str = str(row['english'])\n",
    "    input_str = row\n",
    "    input_str = re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \" \", input_str)\n",
    "    tokens = word_tokenize(input_str)\n",
    "    for word in tokens:\n",
    "        stem_result.append(stemmer.stem(word))\n",
    "    str1 = ' '.join(stem_result)\n",
    "    return str1\n",
    "captions_data['tokenStem'] = captions_data['captions'].apply(tokenize_stem)  \n",
    "bio_data['biography'] = bio_data['biography'].apply(tokenize_stem)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>biography</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>username</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ladyandpups</td>\n",
       "      <td>cookbook art escap cook readi preorder link pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>nelrestaurant</td>\n",
       "      <td>uniqu dine experi full surpris tuck away surri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cookrepublic</td>\n",
       "      <td>award win photograph blogger stylist design co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>annabarnettcooks</td>\n",
       "      <td>cook author even standard contributor food tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dennistheprescott</td>\n",
       "      <td>cook photograph write homemad cookbook eat del...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>eatsmorefun</td>\n",
       "      <td>current featur singapor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>igbrunchclub</td>\n",
       "      <td>use hashtag igbrunchclub chanc featur brunch i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>stevehansenimages</td>\n",
       "      <td>photograph director retouch cg artist shoot fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cookieandkate</td>\n",
       "      <td>celebr whole food find vegetarian recip cookie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           biography\n",
       "username                                                            \n",
       "ladyandpups        cookbook art escap cook readi preorder link pr...\n",
       "nelrestaurant      uniqu dine experi full surpris tuck away surri...\n",
       "cookrepublic       award win photograph blogger stylist design co...\n",
       "annabarnettcooks   cook author even standard contributor food tra...\n",
       "dennistheprescott  cook photograph write homemad cookbook eat del...\n",
       "eatsmorefun                                  current featur singapor\n",
       "igbrunchclub       use hashtag igbrunchclub chanc featur brunch i...\n",
       "stevehansenimages  photograph director retouch cg artist shoot fo...\n",
       "cookieandkate      celebr whole food find vegetarian recip cookie..."
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bio_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(analyzer = \"word\",tokenizer=None,preprocessor = None,stop_words =None,ngram_range = (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_word = count_vectorizer.fit_transform(captions_data['captions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_label = [e[:30]+\"...\" for e in captions_data['captions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorized = pd.DataFrame(doc_word.toarray(), index=ex_label, columns=count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0101</th>\n",
       "      <th>0101 224</th>\n",
       "      <th>010506</th>\n",
       "      <th>010506 3e</th>\n",
       "      <th>0162</th>\n",
       "      <th>0162 blk</th>\n",
       "      <th>0213</th>\n",
       "      <th>0213 cluny</th>\n",
       "      <th>0235</th>\n",
       "      <th>0235 funan</th>\n",
       "      <th>...</th>\n",
       "      <th>zero</th>\n",
       "      <th>zero delay</th>\n",
       "      <th>zest</th>\n",
       "      <th>zest anyone</th>\n",
       "      <th>zesty</th>\n",
       "      <th>zesty even</th>\n",
       "      <th>zettertownhouse</th>\n",
       "      <th>zettertownhouse marylebone</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>zucchini yellow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>thank guys tuning instagram li...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>planning christmas function bi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hot soup nourishing soups dail...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>collab always ted star show sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>monday drip recipe cookbook be...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>black pepper cream crab lingui...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>coffee cake breakfast jacobthe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>yes national mushroom day dess...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>today im rounding thirteen pum...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows √ó 4169 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   0101  0101 224  010506  010506 3e  0162  \\\n",
       "thank guys tuning instagram li...     0         0       0          0     0   \n",
       "planning christmas function bi...     0         0       0          0     0   \n",
       "hot soup nourishing soups dail...     0         0       0          0     0   \n",
       "collab always ted star show sh...     0         0       0          0     0   \n",
       "monday drip recipe cookbook be...     0         0       0          0     0   \n",
       "black pepper cream crab lingui...     1         1       1          1     1   \n",
       "coffee cake breakfast jacobthe...     0         0       0          0     0   \n",
       "yes national mushroom day dess...     0         0       0          0     0   \n",
       "today im rounding thirteen pum...     0         0       0          0     0   \n",
       "\n",
       "                                   0162 blk  0213  0213 cluny  0235  \\\n",
       "thank guys tuning instagram li...         0     0           0     0   \n",
       "planning christmas function bi...         0     0           0     0   \n",
       "hot soup nourishing soups dail...         0     0           0     0   \n",
       "collab always ted star show sh...         0     0           0     0   \n",
       "monday drip recipe cookbook be...         0     0           0     0   \n",
       "black pepper cream crab lingui...         1     1           1     1   \n",
       "coffee cake breakfast jacobthe...         0     0           0     0   \n",
       "yes national mushroom day dess...         0     0           0     0   \n",
       "today im rounding thirteen pum...         0     0           0     0   \n",
       "\n",
       "                                   0235 funan  ...  zero  zero delay  zest  \\\n",
       "thank guys tuning instagram li...           0  ...     1           1     0   \n",
       "planning christmas function bi...           0  ...     0           0     0   \n",
       "hot soup nourishing soups dail...           0  ...     0           0     0   \n",
       "collab always ted star show sh...           0  ...     0           0     1   \n",
       "monday drip recipe cookbook be...           0  ...     0           0     0   \n",
       "black pepper cream crab lingui...           1  ...     0           0     0   \n",
       "coffee cake breakfast jacobthe...           0  ...     0           0     0   \n",
       "yes national mushroom day dess...           0  ...     0           0     0   \n",
       "today im rounding thirteen pum...           0  ...     0           0     0   \n",
       "\n",
       "                                   zest anyone  zesty  zesty even  \\\n",
       "thank guys tuning instagram li...            0      0           0   \n",
       "planning christmas function bi...            0      0           0   \n",
       "hot soup nourishing soups dail...            0      0           0   \n",
       "collab always ted star show sh...            1      0           0   \n",
       "monday drip recipe cookbook be...            0      0           0   \n",
       "black pepper cream crab lingui...            0      0           0   \n",
       "coffee cake breakfast jacobthe...            0      0           0   \n",
       "yes national mushroom day dess...            0      0           0   \n",
       "today im rounding thirteen pum...            0      1           1   \n",
       "\n",
       "                                   zettertownhouse  \\\n",
       "thank guys tuning instagram li...                0   \n",
       "planning christmas function bi...                0   \n",
       "hot soup nourishing soups dail...                0   \n",
       "collab always ted star show sh...                0   \n",
       "monday drip recipe cookbook be...                0   \n",
       "black pepper cream crab lingui...                0   \n",
       "coffee cake breakfast jacobthe...                1   \n",
       "yes national mushroom day dess...                0   \n",
       "today im rounding thirteen pum...                0   \n",
       "\n",
       "                                   zettertownhouse marylebone  zucchini  \\\n",
       "thank guys tuning instagram li...                           0         0   \n",
       "planning christmas function bi...                           0         0   \n",
       "hot soup nourishing soups dail...                           0         0   \n",
       "collab always ted star show sh...                           0         0   \n",
       "monday drip recipe cookbook be...                           0         0   \n",
       "black pepper cream crab lingui...                           0         0   \n",
       "coffee cake breakfast jacobthe...                           1         0   \n",
       "yes national mushroom day dess...                           0         0   \n",
       "today im rounding thirteen pum...                           0         1   \n",
       "\n",
       "                                   zucchini yellow  \n",
       "thank guys tuning instagram li...                0  \n",
       "planning christmas function bi...                0  \n",
       "hot soup nourishing soups dail...                0  \n",
       "collab always ted star show sh...                0  \n",
       "monday drip recipe cookbook be...                0  \n",
       "black pepper cream crab lingui...                0  \n",
       "coffee cake breakfast jacobthe...                0  \n",
       "yes national mushroom day dess...                0  \n",
       "today im rounding thirteen pum...                1  \n",
       "\n",
       "[9 rows x 4169 columns]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-metis] *",
   "language": "python",
   "name": "conda-env-.conda-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
